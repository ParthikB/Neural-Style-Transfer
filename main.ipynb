{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParthikB/Neural-Style-Transfer/blob/v0.3/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYb4w64K_a7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uncomment the following code to mount the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roKFsgZS_VmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.15.0 # Defining which Tf version to use\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from tensorflow.python.keras import models\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "import urllib\n",
        "import statistics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f76I4l_B_b5M",
        "colab_type": "code",
        "outputId": "67bd353d-4681-4739-9e12-5f0c27b49e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Enabling Eager Execution\n",
        "tf.enable_eager_execution()\n",
        "print(\"Eager Execution Initialized:\",tf.executing_eagerly())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eager Execution Initialized: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lOW4Vh9ktyY",
        "colab_type": "text"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYmdVNcLCaCD",
        "colab_type": "text"
      },
      "source": [
        "### Selecting the Feature Layers needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUg3eIQDBgnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the Feature Layers we need respectively\n",
        "styleLayers = ['block1_conv2', \n",
        "               'block2_conv2', \n",
        "               'block3_conv3', \n",
        "               'block4_conv3', \n",
        "               'block5_conv3']\n",
        "\n",
        "contentLayer = ['block3_conv2']\n",
        "\n",
        "\n",
        "numContentLayers = len(contentLayer) # Number of Content Layers\n",
        "numStyleLayers   = len(styleLayers)  # Number of Style Layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyrVfwX-CeKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining Function to import model (VGG19)\n",
        "def getModel():\n",
        "\n",
        "  # Loading Model from tf\n",
        "  model = tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet')\n",
        "  model.trainable = False # Freezing to parameters\n",
        "\n",
        "  # Features of the Respective Layers\n",
        "  contentFeatures = [model.get_layer(name).output for name in contentLayer]\n",
        "  styleFeatures   = [model.get_layer(name).output for name in styleLayers]\n",
        "  \n",
        "  modelOutput = contentFeatures + styleFeatures\n",
        "\n",
        "  return models.Model(model.input, modelOutput)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLOL1qbSDkDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining GRAM MATRIX\n",
        "def gram(x):\n",
        "\n",
        "  # number of channels\n",
        "  channels = int(x.shape[-1])\n",
        "  \n",
        "  # reshaping to channel first\n",
        "  a = tf.reshape(x, [-1, channels])\n",
        "  n = tf.shape(a)[0]\n",
        "  \n",
        "  # gram matrix\n",
        "  gram = tf.matmul(a, a, transpose_a=True)\n",
        "  \n",
        "  return gram / tf.cast(n, tf.float32)\n",
        "\n",
        "\n",
        "# Defining CONTENT COST\n",
        "def contentCost(contentFeatures, generateFeatures):\n",
        "  return tf.reduce_mean(tf.square(contentFeatures-generateFeatures))\n",
        "\n",
        "\n",
        "# Defining STYLE COST\n",
        "def styleCost(styleFeatures, generateFeatures):\n",
        "  styleGram = gram(styleFeatures)\n",
        "  return tf.reduce_mean(tf.square(styleGram - generateFeatures))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OHnNdN10-PE",
        "colab_type": "text"
      },
      "source": [
        "### Image Manipulations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vry1Gt1mEcnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Helper function to compute our content and style feature representations.\n",
        " \n",
        "  This function will simply load and preprocess both the content and style \n",
        "  images from their path. Then it will feed them through the network to obtain\n",
        "  the outputs of the intermediate layers. \n",
        "  \n",
        "  Arguments:\n",
        "    model: The model that we are using.\n",
        "    content_path: The path to the content image.\n",
        "    style_path: The path to the style image\n",
        "    \n",
        "  Returns:\n",
        "    returns the style features and the content features. \n",
        "  \"\"\"\n",
        "\n",
        "def getFeatures(contentPath, stylePath, model):\n",
        "  \n",
        "  # Loading and pre-processing the images\n",
        "  _, content = inputImageAndPreprocess(contentPath)\n",
        "  _, style     = inputImageAndPreprocess(stylePath)\n",
        "\n",
        "  # Defining the respective outputs from our model\n",
        "  contentOutputs = model(content)\n",
        "  styleOutputs = model(style)\n",
        "  \n",
        "  # Extracting out the different features from the model output\n",
        "  contentFeatures = [contentFeature[0] for contentFeature in contentOutputs[numStyleLayers:]]\n",
        "  styleFeatures = [styleFeature[0] for styleFeature in styleOutputs[:numStyleLayers]]\n",
        "\n",
        "  return contentFeatures, styleFeatures\n",
        "\n",
        "\n",
        "def loadImage(path_to_img):\n",
        "  max_dim = 512\n",
        "  img2show = Image.open(path_to_img)\n",
        "  long = max(img2show.size)\n",
        "  scale = max_dim/long\n",
        "  img = img2show.resize((round(img2show.size[0]*scale), round(img2show.size[1]*scale)), Image.ANTIALIAS)\n",
        "  \n",
        "  img = image.img_to_array(img)\n",
        "  \n",
        "  # We need to broadcast the image array such that it has a batch dimension \n",
        "  img = np.expand_dims(img2show, axis=0)\n",
        "  return img2show, img\n",
        " \n",
        "\n",
        "def urlToImage(url):\n",
        "  resp = urllib.request.urlopen(url)\n",
        "  img = np.asarray(bytearray(resp.read()), dtype='uint8')\n",
        "  img = cv2.imdecode(img, cv2.IMREAD_COLOR)\n",
        "  img2show = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  img = np.expand_dims(img2show, axis=0)\n",
        "  return img2show, img\n",
        " \n",
        "\n",
        "def inputImageAndPreprocess(path):\n",
        "  # Loading the image and reshaping it according to VGG19 requirements.\n",
        "  if path[:5]=='https':\n",
        "    print(\"Loading Image from Internet...\")\n",
        "    img2show, img = urlToImage(path)\n",
        "  else:\n",
        "    print(\"Loading Image from Local...\")\n",
        "    img2show, img = loadImage(path)\n",
        "  \n",
        "  # Preprocessing the img according to VGG19 requirements\n",
        "  img = tf.keras.applications.vgg19.preprocess_input(img)\n",
        "\n",
        "  return img2show, img\n",
        "\n",
        "\n",
        "# Deprocessing Image to save locally\n",
        "def deprocessImage(processed_img):\n",
        "  x = processed_img.copy()\n",
        "  if len(x.shape) == 4:\n",
        "    x = np.squeeze(x, 0)\n",
        "  assert len(x.shape) == 3, (\"Input to deprocess image must be an image of \"\n",
        "                             \"dimension [1, height, width, channel] or [height, width, channel]\")\n",
        "  if len(x.shape) != 3:\n",
        "    raise ValueError(\"Invalid input to deprocessing image\")\n",
        "  \n",
        "  # perform the inverse of the preprocessiing step\n",
        "  x[:, :, 0] += 103.939\n",
        "  x[:, :, 1] += 116.779\n",
        "  x[:, :, 2] += 123.68\n",
        "  x = x[:, :, ::-1]\n",
        "\n",
        "  x = np.clip(x, 0, 255).astype('uint8')\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G--g9kADOCuI",
        "colab_type": "text"
      },
      "source": [
        "### Computing the total Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3bx7mzlonff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def totalLoss(model, lossWeights, generateImage, contentFeatures, styleFeatures):\n",
        "\n",
        "  # Extracting the respective weights\n",
        "  contentWeight, styleWeight = lossWeights\n",
        "\n",
        "  # Extracting the generate image features from the model\n",
        "  modelOutputs = model(generateImage)\n",
        "\n",
        "  # Splitting the generate Features into different categories\n",
        "  contentGenerateFeatures = modelOutputs[numStyleLayers:]\n",
        "  styleGenerateFeatures   = modelOutputs[:numStyleLayers]\n",
        "\n",
        "  # Initializing all costs with 0\n",
        "  contentCostValue, styleCostValue = 0, 0\n",
        "\n",
        "  # Defining partial weights\n",
        "  contentWeightPerLayer = 1.0 / float(numContentLayers)\n",
        "  styleWeightPerLayer = 1.0 / float(numStyleLayers)\n",
        "\n",
        "  # Computing Content Cost\n",
        "  for generateContent, combinationContent in zip(contentFeatures, contentGenerateFeatures):\n",
        "    contentCostValue += contentWeightPerLayer * contentCost(combinationContent[0], generateContent)\n",
        "\n",
        "  # Computing Style Cost for every layer\n",
        "  for generateStyle, combinationStyle in zip(styleFeatures, styleGenerateFeatures):\n",
        "    styleCostValue += styleWeightPerLayer * styleCost(combinationStyle[0], generateStyle)\n",
        "  \n",
        "\n",
        "  # Assigning the weights\n",
        "  contentCostValue *= contentWeight\n",
        "  styleCostValue *= styleWeight\n",
        "\n",
        "  # Computing the Total Loss\n",
        "  totalLossValue = contentCostValue + styleCostValue\n",
        "\n",
        "  return totalLossValue, contentCostValue, styleCostValue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5m_rbo5OGnU",
        "colab_type": "text"
      },
      "source": [
        "### Computing the Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkuJHoGOtQkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computeGrads(config):\n",
        "  with tf.GradientTape() as tape:\n",
        "    allLoss = totalLoss(**config)\n",
        "\n",
        "  loss = allLoss[0]\n",
        "\n",
        "  return tape.gradient(loss, config['generateImage']), allLoss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvR3F1KBvBx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "FUNTIONS DEFINED SO FAR:\n",
        "\n",
        "  > getModel()\n",
        "  > gram()\n",
        "  > contentCost()\n",
        "  > styleCost()\n",
        "  > getFeatures()\n",
        "  > load_img()\n",
        "  > inputImageAndPreprocess()\n",
        "  > totalLoss()\n",
        "  > computeGrads()\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBBVPtneLdxK",
        "colab_type": "text"
      },
      "source": [
        "### Time to get it all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWMyORWOuPhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the MAIN TRAINING FUNCTION\n",
        "def runStyleTransfer(contentPath,\n",
        "                     stylePath,\n",
        "                     iterations     = 1000,\n",
        "                     SAVE_EVERY     = 1,\n",
        "                     contentWeight  = 1e3,\n",
        "                     styleWeight    = 1e-2,\n",
        "                     output_dirName = 'output'):\n",
        "    \n",
        "  # Importing the Model\n",
        "  model = getModel()\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  # Extracting out the respective features from the model\n",
        "  contentFeatures, styleFeatures = getFeatures(contentPath, stylePath, model)\n",
        "  styleFeatures = [gram(styleFeature) for styleFeature in styleFeatures]\n",
        "\n",
        "  # Creating the Generate Image\n",
        "  _ , generateImage = inputImageAndPreprocess(contentPath)\n",
        "  generateImage = tf.Variable(generateImage, dtype=tf.float32)\n",
        "\n",
        "  # Defining the Adam Optimizer\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=5, epsilon=1e-3)\n",
        "\n",
        "  # Storing the best Image and Loss\n",
        "  bestLoss, bestImage = float('inf'), None\n",
        "\n",
        "  # Zipping the Weights\n",
        "  lossWeights = (contentWeight, styleWeight)\n",
        "  \n",
        "  # Defining the Config File\n",
        "  config = {\n",
        "    'model': model,\n",
        "    'lossWeights': lossWeights,\n",
        "    'generateImage': generateImage,\n",
        "    'contentFeatures': contentFeatures,\n",
        "    'styleFeatures': styleFeatures\n",
        "    }\n",
        "  \n",
        "  globalStart = time.time()\n",
        "  \n",
        "  normMeans = np.array([103.939, 116.779, 123.68])\n",
        "  minVals = -normMeans\n",
        "  maxVals = 255 - normMeans  \n",
        "\n",
        "  # Creating Logs to use for Plotting Later\n",
        "  contentCostLog, styleCostLog, totalCostLog = [], [], []\n",
        "\n",
        "  ETA = 0\n",
        "  timeLog = []\n",
        "\n",
        "  PATH = f'/content/drive/My Drive/Colab Notebooks/Neural Style Transfer/output/{output_dirName}'\n",
        "  if not os.path.isdir(PATH):\n",
        "    os.mkdir(PATH)\n",
        "  os.chdir(PATH)\n",
        "\n",
        "  for iter in range(iterations):\n",
        "    startTime = time.time()\n",
        "\n",
        "    # Computing the Grads and Loss\n",
        "    grads, allLoss = computeGrads(config)\n",
        "\n",
        "    # Extracting different kinds of Losses\n",
        "    loss, contentLoss, styleLoss = allLoss\n",
        "    \n",
        "    # Saving the respective losses in respective lists for plotting\n",
        "    contentCostLog.append(contentLoss)\n",
        "    styleCostLog.append(styleLoss)\n",
        "    totalCostLog.append(loss)\n",
        "\n",
        "    # Applying gradients to Generate Image\n",
        "    optimizer.apply_gradients([(grads, generateImage)])\n",
        "\n",
        "    # Clipping the values of Generate Image from (-255, 255)\n",
        "    clipped = tf.clip_by_value(generateImage, minVals, maxVals)\n",
        "    generateImage.assign(clipped)\n",
        "\n",
        "    endTime = time.time()\n",
        "\n",
        "    timeTakenbyOneImage = endTime - startTime\n",
        "    timeLog.append(timeTakenbyOneImage)\n",
        "\n",
        "    ETA = statistics.mean(timeLog) * (iterations-iter)\n",
        "\n",
        "    # Updating the Best Image and Loss\n",
        "    if loss < bestLoss:\n",
        "      bestLoss = loss\n",
        "      bestImage = generateImage.numpy()\n",
        "\n",
        "    # Saving the Generate Image\n",
        "    if iter % SAVE_EVERY == 0:\n",
        "      new = cv2.cvtColor(deprocessImage(generateImage.numpy()), cv2.COLOR_RGB2BGR)\n",
        "      cv2.imwrite(f'generateImage_{iter+1}.jpg', new)\n",
        "\n",
        "      print(f\"Image {iter+1} Saved || Time Taken: {round(timeTakenbyOneImage, 2)} sec || ETA: {round(ETA/60, 2)} min\" )\n",
        "    \n",
        "\n",
        "  # Saving the numpy Arrays to plot later\n",
        "  np.save('contentLoss.npy', contentCostLog)\n",
        "  np.save('styleLoss.npy', styleCostLog)\n",
        "  np.save('totalCostLoss.npy', totalCostLog)\n",
        "\n",
        "  print('Total Time taken in training :', round(endTime-globalStart, 2))\n",
        "\n",
        "  return bestImage, bestLoss, output_dirName\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFMQ6znrMY3y",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing our Content And Style Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpXligxdVBFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Style Templates:\n",
        "  > Wave : https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQ8LOCDfTvcJ_V4fBdtL3R_oQn7D9P96PPzJFCksdWeKHHhyfUZ\n",
        "  > Seated Nude : https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQ0ip7KMW5XB_qhU3cwBDDd1fjlogHfgOxw9gnVq2CqZdLwHgY3\n",
        "'''\n",
        "\n",
        "# Enter the path of the respective Images\n",
        "contentImagePath = '/content/drive/My Drive/Colab Notebooks/Neural Style Transfer/images/kingStarry.jpg'\n",
        "styleImagePath   = '/content/drive/My Drive/Colab Notebooks/Neural Style Transfer/images/style5.jpg'\n",
        "\n",
        "content, var = inputImageAndPreprocess(contentImagePath)\n",
        "style, var   = inputImageAndPreprocess(styleImagePath)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(content)\n",
        "plt.title('Content Image')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(style)\n",
        "plt.title('Style Image')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "117gi_T-MneQ",
        "colab_type": "text"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPGdWaG43zMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ITERATIONS = 2500\n",
        "\n",
        "bestImage, bestLoss, output_dirName = runStyleTransfer(contentImagePath,\n",
        "                                                      styleImagePath,\n",
        "                                                      iterations=ITERATIONS,\n",
        "                                                      SAVE_EVERY = 5,\n",
        "                                                      contentWeight = 1,\n",
        "                                                      styleWeight=0.8,\n",
        "                                                      output_dirName = 'kingStarry')\n",
        "\n",
        "# Output Cleared for Fairness"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzkI-DB6M5Wj",
        "colab_type": "text"
      },
      "source": [
        "#### Visualizing the Best Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ywRuBn7fHpkP",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(deprocessImage(bestImage))\n",
        "plt.title('Generated Image')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BIqrewkNBxJ",
        "colab_type": "text"
      },
      "source": [
        "#### Plotting the Cost Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWwPVBHGHzfG",
        "colab_type": "code",
        "outputId": "8d21cc2c-373a-4b86-bea3-fff91c3ec071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "PATH = f'/content/drive/My Drive/Colab Notebooks/Neural Style Transfer/output/{output_dirName}'\n",
        "os.chdir(PATH)\n",
        "contentLog = np.load('contentLoss.npy')\n",
        "print('Content Log Loaded..!')\n",
        "styleLog = np.load('styleLoss.npy')\n",
        "print('Style Log Loaded..!')\n",
        "totalLog = np.load('totalCostLoss.npy')\n",
        "print('Total Loss Log Loaded..!')\n",
        "iterations = list(range(1, len(styleLog)+1))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Content Log Loaded..!\n",
            "Style Log Loaded..!\n",
            "Total Loss Log Loaded..!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpxrPjPH-AJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(23, 8))\n",
        "plt.plot(totalLog,   linewidth=3, label='total loss')\n",
        "plt.plot(styleLog,   linewidth=1, label='style loss')\n",
        "plt.plot(contentLog, linewidth=2, label='content loss')\n",
        "# plt.plot(learning_curve_tv, linewidth=2, label='total variation loss')\n",
        "plt.title(\"Learning curve\")\n",
        "plt.ylabel(\"error\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.yscale(\"log\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}